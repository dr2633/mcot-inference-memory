**Awesome LLM Strawberry**
https://github.com/hijkzzz/Awesome-LLM-Strawberry?tab=readme-ov-file

CoT Hub 
https://github.com/FranxYao/chain-of-thought-hub

Chain-of-Thought  (Github Match)
https://github.com/topics/chain-of-thought

o1 Reasoning Docs 
https://github.com/hijkzzz/Awesome-LLM-Strawberry

Open-o1 
https://github.com/Open-Source-O1/Open-O1
 
QWEN2.5
https://arxiv.org/pdf/2409.12122

Less is More for RL Scaling 
https://arxiv.org/abs/2502.11886
https://github.com/GAIR-NLP/LIMR

Logic-RL: Unleashing LLM Reasoning with Rule-Based Reinforcement Learning
https://arxiv.org/pdf/2502.14768

Scaling Test-Time Compute without RL is Suboptimal 
https://arxiv.org/abs/2502.12118

Fine-Tuning Vision-Language Models as Decision-Making AGents 
https://arxiv.org/abs/2405.10292

Large Language Monkeys: Scaling Inference Compute with Repeated Sampling 
https://arxiv.org/pdf/2407.21787

Learn Deeply and Don't Overthink 
https://arxiv.org/abs/2412.21187


Models

[Alibaba Qwen Team] QwQ
https://huggingface.co/Qwen/QwQ-32B-Preview

[Alibaba Qwen Team] QvQ
[DeepSeek] DeepSeek R1
[OpenO1 Team] Open-Source O1
[NovaSky] Sky-T1
[GAIR-NLP] O1 Replication Journey: A Strategic Progress Report
[Tencent] DRT-o1
[Skywork] Skywork o1 Open model series
[Alibaba] Marco-o1
[CUHK-SZ] HuatuoGPT-o1
[Steiner] A Small Step Towards Reproducing OpenAI o1: Progress Report on the Steiner Open Source Models


[OpenAI] Introducing deep research
[OpenAI] o3 preview & o3 mini
[OpenAI] Introducing ChatGPT Pro
[Google DeepMind] Gemini 2.0 Flash Thinking
[Ilya Sutskever] AI with reasoning power will be less predictable
[SemianAlysis] Scaling Laws – O1 Pro Architecture, Reasoning Training Infrastructure, Orion and Claude 3.5 Opus “Failures”
[DeepSeek] DeepSeek-R1-Lite-Preview is now live: unleashing supercharged reasoning power!
[Moonshoot] 数学对标o1系列，搜索再次进化，Kimi 新推理模型与你一起拓展智能边界
[Moonshoot] Kimi 发布视觉思考模型 k1，多项理科测试行业领先
[InternLM] 强推理模型书生InternThinker开放体验：自主生成高智力密度数据、具备元动作思考能力
[新智元] 万字独家爆光，首揭o1 pro架构！惊人反转，Claude 3.5 Opus没失败？


[OpenAI] Learning to Reason with LLMs
[OpenAI] OpenAI o1-mini Advancing cost-efficient reasoning
[OpenAI] Finding GPT-4’s mistakes with GPT-4
[ARC-AGI] OpenAI o3 Breakthrough High Score on ARC-AGI-Pub
[Anthropic] Building effective agents
[Tibor Blaho] Summary of what we have learned during AMA hour with the OpenAI o1 team
[hijkzzz] Exploring OpenAI O1 Model Replication
[hijkzzz] A Survey of Reinforcement Learning from Human Feedback (RLHF)
[Nathan Lambert] OpenAI’s Strawberry, LM self-talk, inference scaling laws, and spending more on inference
[Nathan Lambert] Reverse engineering OpenAI’s o1
[Andreas Stuhlmüller, jungofthewon] Supervise Process, not Outcomes
[Nouha Dziri] Have o1 Models Cracked Human Reasoning?
[Rishabh Agarwal] Improving LLM Reasoning using Self-generated data: RL and Verifiers
[Wei Shen] Generalization Progress in RLHF: Insights into the Impact of Reward Models and PPO
[Dominater069] Codeforces - Analyzing how good O1-Mini actually is
[hijkzzz] o1 复现以及关于 REINFORCE & GRPO 的碎碎念


[Noam Brown] Parables on the Power of Planning in AI: From Poker to Diplomacy
[Noam Brown] OpenAI o1 and Teaching LLMs to Reason Better
[Hyung Won Chung] Don't teach. Incentivize.


[DeepLearning.AI] Reasoning with o1

OpenAI Developers
All the questions addressed by the API team during the December 17, 2024 AMA
We’re hosting an AMA for developers from 10–11 AM PT today.
Today we previewed Reinforcement Fine-Tuning
